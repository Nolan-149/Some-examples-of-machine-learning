{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Chap06_1_Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#模型评价指标与metrics模块\" data-toc-modified-id=\"模型评价指标与metrics模块-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>模型评价指标与metrics模块</a></span><ul class=\"toc-item\"><li><span><a href=\"#分类指标\" data-toc-modified-id=\"分类指标-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>分类指标</a></span><ul class=\"toc-item\"><li><span><a href=\"#导入数据\" data-toc-modified-id=\"导入数据-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>导入数据</a></span><ul class=\"toc-item\"><li><span><a href=\"#数据说明\" data-toc-modified-id=\"数据说明-1.1.1.1\"><span class=\"toc-item-num\">1.1.1.1&nbsp;&nbsp;</span>数据说明</a></span></li><li><span><a href=\"#读入数据\" data-toc-modified-id=\"读入数据-1.1.1.2\"><span class=\"toc-item-num\">1.1.1.2&nbsp;&nbsp;</span>读入数据</a></span></li><li><span><a href=\"#数值编码\" data-toc-modified-id=\"数值编码-1.1.1.3\"><span class=\"toc-item-num\">1.1.1.3&nbsp;&nbsp;</span>数值编码</a></span></li><li><span><a href=\"#数据探索\" data-toc-modified-id=\"数据探索-1.1.1.4\"><span class=\"toc-item-num\">1.1.1.4&nbsp;&nbsp;</span>数据探索</a></span></li></ul></li><li><span><a href=\"#划分数据集-train，test\" data-toc-modified-id=\"划分数据集-train，test-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>划分数据集 train，test</a></span></li><li><span><a href=\"#分类模型—逻辑回归\" data-toc-modified-id=\"分类模型—逻辑回归-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>分类模型—逻辑回归</a></span></li><li><span><a href=\"#clf指标1：accuracy\" data-toc-modified-id=\"clf指标1：accuracy-1.1.4\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;</span>clf指标1：accuracy</a></span></li><li><span><a href=\"#clf指标2：precision、recall和𝐹1值的计算\" data-toc-modified-id=\"clf指标2：precision、recall和𝐹1值的计算-1.1.5\"><span class=\"toc-item-num\">1.1.5&nbsp;&nbsp;</span>clf指标2：precision、recall和𝐹1值的计算</a></span></li><li><span><a href=\"#clf指标3：confusion_matrix\" data-toc-modified-id=\"clf指标3：confusion_matrix-1.1.6\"><span class=\"toc-item-num\">1.1.6&nbsp;&nbsp;</span>clf指标3：confusion_matrix</a></span></li><li><span><a href=\"#clf指标4:classification_report\" data-toc-modified-id=\"clf指标4:classification_report-1.1.7\"><span class=\"toc-item-num\">1.1.7&nbsp;&nbsp;</span>clf指标4:classification_report</a></span></li><li><span><a href=\"#clf指标5:P-R曲线\" data-toc-modified-id=\"clf指标5:P-R曲线-1.1.8\"><span class=\"toc-item-num\">1.1.8&nbsp;&nbsp;</span>clf指标5:P-R曲线</a></span></li><li><span><a href=\"#clf指标6:ROC曲线与AUC值\" data-toc-modified-id=\"clf指标6:ROC曲线与AUC值-1.1.9\"><span class=\"toc-item-num\">1.1.9&nbsp;&nbsp;</span>clf指标6:ROC曲线与AUC值</a></span></li><li><span><a href=\"#clf指标7:log_loss(对数损失)\" data-toc-modified-id=\"clf指标7:log_loss(对数损失)-1.1.10\"><span class=\"toc-item-num\">1.1.10&nbsp;&nbsp;</span>clf指标7:log_loss(对数损失)</a></span></li><li><span><a href=\"#clf指标8:hinge_loss(合页损失)\" data-toc-modified-id=\"clf指标8:hinge_loss(合页损失)-1.1.11\"><span class=\"toc-item-num\">1.1.11&nbsp;&nbsp;</span>clf指标8:hinge_loss(合页损失)</a></span></li></ul></li><li><span><a href=\"#回归指标\" data-toc-modified-id=\"回归指标-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>回归指标</a></span><ul class=\"toc-item\"><li><span><a href=\"#导入数据\" data-toc-modified-id=\"导入数据-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>导入数据</a></span></li><li><span><a href=\"#rm指标\" data-toc-modified-id=\"rm指标-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>rm指标</a></span></li></ul></li><li><span><a href=\"#聚类指标\" data-toc-modified-id=\"聚类指标-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>聚类指标</a></span><ul class=\"toc-item\"><li><span><a href=\"#导入数据\" data-toc-modified-id=\"导入数据-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>导入数据</a></span></li><li><span><a href=\"#K-means聚类\" data-toc-modified-id=\"K-means聚类-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>K-means聚类</a></span></li><li><span><a href=\"#cluster指标1:轮廓系数\" data-toc-modified-id=\"cluster指标1:轮廓系数-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>cluster指标1:轮廓系数</a></span></li><li><span><a href=\"#cluster指标2：兰德系数\" data-toc-modified-id=\"cluster指标2：兰德系数-1.3.4\"><span class=\"toc-item-num\">1.3.4&nbsp;&nbsp;</span>cluster指标2：兰德系数</a></span></li></ul></li></ul></li><li><span><a href=\"#模型选择与model_selection模块\" data-toc-modified-id=\"模型选择与model_selection模块-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>模型选择与model_selection模块</a></span><ul class=\"toc-item\"><li><span><a href=\"#交叉验证\" data-toc-modified-id=\"交叉验证-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>交叉验证</a></span><ul class=\"toc-item\"><li><span><a href=\"#Kfold与StratifiedKFold分类器\" data-toc-modified-id=\"Kfold与StratifiedKFold分类器-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Kfold与StratifiedKFold分类器</a></span></li><li><span><a href=\"#ShuffleSplit分类器\" data-toc-modified-id=\"ShuffleSplit分类器-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>ShuffleSplit分类器</a></span></li></ul></li><li><span><a href=\"#根据交叉验证查看模型参数\" data-toc-modified-id=\"根据交叉验证查看模型参数-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>根据交叉验证查看模型参数</a></span><ul class=\"toc-item\"><li><span><a href=\"#根据交叉验证计算模型score\" data-toc-modified-id=\"根据交叉验证计算模型score-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>根据交叉验证计算模型score</a></span></li><li><span><a href=\"#根据交叉验证查看模型学习曲线\" data-toc-modified-id=\"根据交叉验证查看模型学习曲线-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>根据交叉验证查看模型学习曲线</a></span></li></ul></li><li><span><a href=\"#参数调优\" data-toc-modified-id=\"参数调优-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>参数调优</a></span><ul class=\"toc-item\"><li><span><a href=\"#网格搜索\" data-toc-modified-id=\"网格搜索-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>网格搜索</a></span></li><li><span><a href=\"#随机网格搜索\" data-toc-modified-id=\"随机网格搜索-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>随机网格搜索</a></span></li></ul></li></ul></li><li><span><a href=\"#小结\" data-toc-modified-id=\"小结-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>小结</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sklearn06_1_模型选择与评价指标**\n",
    "\n",
    "**案例描述：** <br>\n",
    "> 本案例为《机器学习实践》第六章模型选择与参数调优的课程配套案例代码，主要介绍sklearn中的评价指标与模型选择模块的使用方法。\n",
    "\n",
    "**知识点：** <br>\n",
    "> + 模型评价指标与metrics模块\n",
    ">> + ▶分类指标<br>\n",
    ">> + ▶回归指标<br>\n",
    ">> + ▶聚类指标<br>\n",
    "> + 模型选择与model_selection模块\n",
    ">> + ▶交叉验证  <br>\n",
    ">>>  + (1)交叉验证（cross validation）<br>\n",
    ">>>  + (2)分层k折交叉验证（stratified cross validation）<br>\n",
    ">> + ▶参数调优<br>\n",
    ">>> + (1)网格搜索交叉验证（GridSearchCV）：以穷举的方式遍历所有可能的参数组合 <br>\n",
    ">>> + (2) 随机搜索交叉验证（RandomizedSearchCV）：依据某种分布对参数空间采样，随机的得到一些候选参数组合方案\n",
    "\n",
    "**数据集：**\n",
    "> + 数据集1：汽车满意度数据集\n",
    ">> + `file1_path = \"./dataSets/data_chap6/Car.csv\"`   <br>\n",
    "> + 数据集2：保险   <br>\n",
    ">> + `file2_path = \"./dataSets/data_chap6/insurance.csv\"`  <br>\n",
    "> +  数据集3：汽车   <br>\n",
    ">> + `file3_path =\"./dataSets/data_chap6/Auto.csv\"`\t  <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0 导入库：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams['font.sans-serif']=['SimHei']   #用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus']=False     #用来正常显示负号"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型评价指标与metrics模块\n",
    "\n",
    "## 分类指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据\n",
    "#### 数据说明\n",
    "> **●数据集**\n",
    ">> + 数据一共包含6个特征，1个类别变量（即汽车满意度），共1728个样本点。<br>\n",
    ">> + 本地地址：`file_path = \"./dataSets/data_chap6/CarEvaluation.csv\"`<br>\n",
    "\n",
    "|特征|说明|\n",
    "|-----:|-----:|\n",
    "|buying|购买价格（1：low；2：med；3：high；4：vhigh）|\n",
    "|maint|保养价格（1：low；2：med；3：high；4：vhigh）|\n",
    "|doors|门的个数（1：2；2：3；3：4；4：5more）|\n",
    "|persons|载客数（1：2；2：4；3：more）|\n",
    "|lug_boot|车身的大小（1：small；2：med；3：big）|\n",
    "|safety|安全等级（1：low；2：med；3：high）|\n",
    "|car_acceptability|汽车满意度（1：unacc；0：acc）|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "file1_path = \"./dataSets/data_chap6/CarEvaluation.csv\"\n",
    "raw_data = pd.read_csv(file1_path)\n",
    "# 查看前5\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看基本信息info\n",
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**↑♎分析：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数值编码\n",
    "> 需要对object(非数值)特征进行数值编码，在此之前，先考察一下各个特征的unique()值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建字典存放各特征的唯一值\n",
    "unique_data = {}\n",
    "# 获取数据的特征名\n",
    "col_s = raw_data._________\n",
    "# 遍历各特征，求其unique()\n",
    "for col in col_s:\n",
    "    unique_data[col]=__________________\n",
    "unique_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**↑♎分析：** 根据项目要求，只预测'unacc'和'acc'两类，所以'car_acceptability'特征中的“vgood”与“good”都应该属于“acc”。需要进行`replace()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace操作，\"vgood\":\"acc\",\"good\":\"acc\"\n",
    "raw_data['car_acceptability'].__________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再次查看特征'car_acceptability'的unique()\n",
    "raw_data['car_acceptability']._________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**特征数值编码：** \n",
    "> + 有序特征做数值编码可使用`LabelEncoder`或者`map()`;  无序特征做数值编码可使用`OneHot`或`pd.get_dummies()`\n",
    "> + 根据要求对`'buying', 'maint', 'doors', 'persons', 'lug_boot', 'satety','car_acceptability'`做`map()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "data['buying'] = raw_data['buying'].map({'vhigh':4, 'high':3, 'med':2, 'low':1})\n",
    "data['maint'] = raw_data['maint'].map({'vhigh':4, 'high':3, 'med':2, 'low':1})\n",
    "data['doors'] = raw_data['doors'].map({'2':1, '3':2, '4':3, '5more':4})\n",
    "data['persons'] = raw_data['persons'].map({'2':1, '4':2, 'more':3})\n",
    "data['lug_boot'] = raw_data['lug_boot'].map({'small':1, 'med':2, 'big':3})\n",
    "data['satety'] = raw_data['satety'].map({'high':3, 'med':2, 'low':1})\n",
    "data['car_acceptability'] = raw_data['car_acceptability'].map({'unacc':1, 'acc':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看data前5\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**将`data`写入新的文件中，路径为`“./dataSets/data_chap6/car.csv”`**\n",
    "> 注意：python新建文件不区分大小写，“Car.csv”和“car.csv”认为是同一个。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 写入文件\n",
    "data.to_csv(\"./dataSets/data_chap6/car.csv\",index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**读数据`./dataSets/data_chap6/car.csv`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再次读取\n",
    "data = pd.read_csv(\"./dataSets/data_chap6/car.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 观察目标特征('car_acceptability')的分布\n",
    "data________.________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 类别分布条形图\n",
    "plt.figure(figsize=(8, 6))\n",
    "fig = data.car_acceptability.value_counts().plot(kind='bar', rot=360, \n",
    "                                                 color = [\"blue\",'y'],fontsize=20,\n",
    "                                                 title='汽车满意度类别分布条形图',)\n",
    "plt.xticks([1, 0], ['满意', '不满意'])\n",
    "fig.title.set_size(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分数据集 train，test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集划分\n",
    "from ____________ import train_test_split\n",
    "## 分类X与y('car_acceptability')\n",
    "X = data.____________\n",
    "y = data['car_acceptability']\n",
    "## 划分train与test(8:2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, ____________, random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分类模型—逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入LogisticRegression\n",
    "from ____________ import LogisticRegression\n",
    "\n",
    "## 模型构建与拟合,平衡类别权重\n",
    "clf = LogisticRegression(random_state=10, ____________)\n",
    "clf.fit(X_train, y_train)\n",
    "# 模型预测\n",
    "y_pred = ____________\n",
    "# 分类正确率\n",
    "print(\"分类正确率：\",round(____________,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "警告原因：\n",
    "> + LogisticRegerssion算法的solver支持以下几个参数：\n",
    ">> + solver : 字符串,取值 {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'},默认是 'liblinear'.\n",
    ">> + 如果数据集比较小，则 'liblinear'是很好的选择； 如果数据集很大，用'sag' and 'saga'；\n",
    ">> + 如果是多分类任务，则用'newton-cg', 'sag', 'saga' and 'bfgs'；而'liblinear'只能用于二分类问题;\n",
    ">> + 'newton-cg', 'lbfgs' and 'sag'只处理 L2 范式的正则项，而 'liblinear' and 'saga' 只处理 L1范式的正则项.\n",
    "> +  这里的警告，是建议采用 ‘lbfgs’\n",
    "\n",
    "解决方法：\n",
    "> + `clf = LogisticRegression(solver='lbfgs',random_state=10, class_weight ='balanced')`\n",
    "> + 我们目前的任务就是一个二分类问题，而且数据量不大，所以就不改了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**各指标的意义：**\n",
    "> + 参考：https://www.cnblogs.com/XDU-Lakers/p/12031585.html\n",
    "> + 查准率与查全率的应用场合：https://blog.csdn.net/qq_43827595/article/details/120823576\n",
    "> ![](./imgs/chap06/fig06_01.png)\n",
    "**函数主要参数：**\n",
    "> \n",
    "|参数\t|说明|\n",
    "|---:|---:|\n",
    "|y_true\t|真实标签|\n",
    "|y_pred\t|预测标签|\n",
    "|pos_label\t|正类的类别标记，默认为1|\n",
    "|average\t|一个字符串，用于多分类问题|\n",
    "\n",
    "> 参数average有如下选项:\n",
    ">> ‘binary’（默认）：二分类问题  <br>\n",
    "‘micro’：针对多分类，先计算各混淆矩阵对应元素的平均值，再计算评价指标  <br>\n",
    "‘macro’：针对多分类，先在各混淆矩阵上分别计算出评价指标，再计算其平均值  <br>\n",
    "‘weighted’：在‘macro’基础上考虑类别不平衡问题，加上权重计算评价指标  <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clf指标1：accuracy\n",
    "> + **分类正确率**:预测正确的结果占总样本的百分比; 属于粗粒度评判，样本不平衡时会导致虽然高准确率但无意义，即准确率失效<br>\n",
    "> + 计算公式：` Acc=(TP+TN)/(TP+TN+FN+FP)`,sklearn中的使用方法有两种：\n",
    ">> + (1) 可以不用`y_pred`，直接使用`clf.score(X_test,y_test)`   \n",
    ">> + (2) 有了`y_pred`后，可以使用`metrics.accuracy_score(y_test,y_pred)` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入accuracy_score\n",
    "from ___________ import accuracy_score\n",
    "print(\"分类正确率：\",round(___________,4))\n",
    "\n",
    "## 设置参数normalize=Fasle，可输出分类正确的样本个数\n",
    "print(\"分类正确的样本数：\",round(accuracy_score(y_test,y_pred,___________),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**↑♎分析：**1728 * 0.2 * 0.8468 = 292.65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clf指标2：precision、recall和𝐹1值的计算\n",
    "> + 分类精准率(**查准率**): 针对预测结果，在模型预测为正的样本中真正为正的占多少<br>\n",
    ">> + `Prec=TP/(TP+FP)`, **反应的是正样本预测正确的把握程度,猜的越准越好** \n",
    "> + 分类召回率(**查全率**):，是针对原样本而言的，含义是在实际为正的样本中被预测为正样本的概率，\n",
    ">> + `Recall=TP/(TP+FN)`, **原则\"宁可错杀一千，绝不放过一个\"**\n",
    "> + 精准率和召回率的分子是相同，都是TP，但分母是不同的, 我们希望查准率和查全率同时都非常高。但实际上这两个指标是一对矛盾体，无法做到双高。见后续的P-R曲线。\n",
    "> + 分类F1值: P与R的调和平均，即：`2*(1/(1/P+1/R))`F1分数的。\n",
    ">> + `F1 = 2*查准率*查全率 / (查准率+查全率)` <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入precision_score,recall_score,f1_score\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "print(\"分类精确率：\",round(___________ ,4))\n",
    "print(\"分类召回率：\",round(___________ ,4))\n",
    "print(\"分类F1值：\",round(___________ ,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 设置参数pos_label=1,查看1类的F1\n",
    "print(\"分类F1值：\",round(f1_score(y_test,y_pred,___________),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**↑♎分析：** 2 * 0.95 * 0.8327 / (0.95+0.8327) = 0.88749"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clf指标3：confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入confusion_matrix\n",
    "from _______________ import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "## 中文显示\n",
    "sns.set(font=\"SimHei\")\n",
    "\n",
    "ax = sns.heatmap(_______________,\n",
    "            annot=True, fmt='d',\n",
    "            xticklabels=[\"满意(0)\",\"不满意(1)\"],\n",
    "            yticklabels=[\"满意(0)\",\"不满意(1)\"]\n",
    "           )\n",
    "\n",
    "ax.set_ylabel('真实')\n",
    "ax.set_xlabel('预测')\n",
    "ax.set_title('混淆矩阵热力图')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clf指标4:classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入classification_report\n",
    "from ______________ import classification_report\n",
    "print(______________)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 设置参数：labels和target_names,增强可读性\n",
    "print(classification_report(y_test,y_pred,\n",
    "                            labels=[0,1],\n",
    "                            target_names=[\"满意\",\"不满意\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clf指标5:P-R曲线\n",
    "> 前面提到，P和R不可兼得，如果其中一个非常高，另一个肯定会非常低。选取合适的阈值点要根据实际需求，比如我们想要高的R查全率，那么就要牺牲一些P查准率，在保证查全率最高的情况下，查准率也不那么低。\n",
    "> \n",
    "> ![](./imgs/chap06/fig06_02.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入PRC包\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "# 计算模型对X_test的预测概率值：predict_proba()\n",
    "probs = clf.______________ \n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probs的形状\n",
    "probs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**↑♎分析：** 第一列为模型预测label=0的概率，第二列为模型预测label=1的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取第一列\n",
    "probs0 = ______________ \n",
    "# 获取p，r，t，参数：pos_label=0，即label=0的p，r，t\n",
    "precision,recall,thresholds = precision_recall_curve(___________,________,pos_label=0)\n",
    "## 绘制P-R曲线\n",
    "plt.plot(recall, precision)\n",
    "plt.title('P-R曲线')\n",
    "plt.xlabel('召回率')\n",
    "plt.ylabel('精确率')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 阈值情况\n",
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clf指标6:ROC曲线与AUC值\n",
    ">ROC: ROC曲线全称为受试者工作特征曲线 （Receiver Operating Characteristic Curve）<br>\n",
    ">AUC: AUC（Area Under Curve）被定义为ROC曲线下的面积  <br>\n",
    ">> 真正率（TPR） = 灵敏度 = TP/(TP+FN)   <br>\n",
    "假正率（FPR） = 1- 特异度 = FP/(FP+TN)   <br>\n",
    "●其实我们可以发现灵敏度和召回率是一模一样的，只是名字换了而已。  <br>\n",
    "●由于我们比较关心正样本，所以需要查看有多少负样本被错误地预测为正样本，所以使用（1-特异度），而不是特异度。 <br>\n",
    "  \n",
    "> ROC和AUC可以无视样本不平衡   <br>\n",
    ">![](./imgs/chap06/fig06_03.png)\n",
    "\n",
    "> AUC的一般判断标准：\n",
    ">>0.5 - 0.7：效果较低，但用于预测股票已经很不错了   <br>\n",
    "0.7 - 0.85：效果一般   <br>\n",
    "0.85 - 0.95：效果很好    <br>\n",
    "0.95 - 1：效果非常好，但一般不太可能   <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**绘制ROC曲线**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 绘制ROC曲线\n",
    "from sklearn.metrics import roc_curve\n",
    "# 计算模型对X_test的预测概率值predict_proba\n",
    "probs = clf.predict_proba(X_test)\n",
    "# 比较关心正样本，所以取第2列概率值\n",
    "probs_1 = __________\n",
    "# 通过roc_curve()获得fpr，tpr，thresholds\n",
    "fpr,tpr,thresholds = _____________________\n",
    "# 绘图\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('假正率')\n",
    "plt.ylabel('真正率')\n",
    "plt.title('ROC曲线')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**计算AUC的值**\n",
    "> + way1:`metrics.roc_auc_score(y_true,y_score)`\n",
    "\n",
    "|参数\t|说明|\n",
    "|---:|---:|\n",
    "|y_true\t|真实标签|\n",
    "|y_score\t|依次指定每个样本为**正类的概率**|\n",
    "|average\t|一个字符串，用于多分类问题|\n",
    "> + way2:`metrics.auc(fpr,tpr)`\n",
    "\n",
    "|参数\t|说明|\n",
    "|---:|---:|\n",
    "|x\t|折线上点的横坐标，如FPR|\n",
    "|y\t|折线上点的纵坐标，如TPR|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "## way1：auc\n",
    "print(\"(1)auc:\",roc_auc_score(________,________))\n",
    "\n",
    "# 导入auc\n",
    "from sklearn.metrics import auc\n",
    "## way2：auc\n",
    "print(\"(2)auc:\",auc(________,________))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clf指标7:log_loss(对数损失)\n",
    "> + 对数损失(log loss)，又称逻辑损失(logistic loss)或交叉熵损失(cross-entropy loss），常用于评估分类模型的**概率输出**。\n",
    ">> + 二分类问题对数损失函数公式为：$$\n",
    "-\\frac{1}{n} \\sum\\left(y_{i} \\log p_{i}+\\left(1-y_{i}\\right) \\log \\left(1-p_{i}\\right)\\right)\n",
    "$$\n",
    ">>> ●真实标签取值为{0，1}  <br>\n",
    "●$𝑦_𝑖$ 为第𝑖个样本的真实类别  <br>\n",
    "●$𝑝_𝑖$ 表示第𝑖个样本类别为1的概率 <br>\n",
    ">> + **值越小说明模型性能越好**\n",
    "> +  `metrics.log_loss(y_true,y_pred)`\n",
    "\n",
    "|参数\t|说明|\n",
    "|---:|---:|\n",
    "|y_true\t|真实标签|\n",
    "|y_pred\t|预测概率|\n",
    "|normalize\t|默认为True，返回样本对数损失的均值，若为False，返回对数损失的总和|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 使用交叉熵评估分类模型\n",
    "from sklearn.metrics import log_loss\n",
    "print(\"损失函数(交叉熵)：\",log_loss(y_test,probs))\n",
    "print(\"损失函数的总和：\",log_loss(y_test,probs,normalize=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**↑♎分析：** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clf指标8:hinge_loss(合页损失)\n",
    "> + 针对SVM模型:\n",
    "<img src=\"./imgs/chap06/fig06_04.png\" width=70%>\n",
    "> + 合页损失函数不仅要求分类正确，还要求一定的函数间隔，损失才能达到0，是一种要求更高的损失函数。\n",
    "> + `metrics.hinge_loss(y_true,pred_decision)`\n",
    "\n",
    "|参数\t|说明|\n",
    "|---:|---:|\n",
    "|y_true\t|真实标签|\n",
    "|pred_decision\t|使用decision_function 方法的预测结果|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 计算合页损失\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import hinge_loss\n",
    "\n",
    "## 构建SVM(Gaussian)模型\n",
    "ksvm = SVC(random_state=10,gamma='scale')\n",
    "ksvm.fit(X_train,y_train)\n",
    "\n",
    "## 计算损失\n",
    "pred_decision = ksvm.decision_function(X_test)\n",
    "h_loss = hinge_loss(y_test,pred_decision)\n",
    "print(\"SVM模型的合页损失：\",round(h_loss,4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回归指标\n",
    "> + <img src=\"./imgs/chap06/fig06_05.png\" width=70%>\n",
    "> + Sklearn中的对应方法：\n",
    "\n",
    "|方法\t|说明|\n",
    "|---:|---:|\n",
    "|metrics.mean_absolute_error\t|平均绝对误差|\n",
    "|metrics.mean_squared_error\t|均方误差|\n",
    "|metrics.mean_squared_log_error\t|均方对数误差|\n",
    "|metrics.median_absolute_error\t|中值绝对误差|\n",
    "|metrics.r2_score\t|决定系数R^2|\n",
    "\n",
    "> **数据集：美国病人的医疗费用数据集**\n",
    ">> 现有一份基于美国人口普查局调查的1338个保险计划受益者的资料信息数据，预测目标为计划计入的医疗费用charge.\n",
    "\n",
    ">>|特征\t|说明|\n",
    "|---:|---:|\n",
    "|age\t |受益者的年龄（不包括超过64岁的人）|\n",
    "|sex\t |性别|\n",
    "|bmi\t |身体质量指数，等于体重（公斤）除以身高（米）的平方|\n",
    "|children\t |受益者孩子的数量|\n",
    "|smoker\t |是否吸烟|\n",
    "|region\t |在美国的居住地|\n",
    "|charges\t |医疗费用|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2_path = \"./dataSets/data_chap6/insurance.csv\"\n",
    "\n",
    "#读取美国病人的医疗费用数据集\n",
    "insurance = pd.read_csv(file2_path)\n",
    "insurance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**特征编码：**\n",
    "> 需要对特征`sex`,`smoker`,`region`进行OneHot编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_OneHot = pd.__________________________________\n",
    "data_OneHot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果想保留原特征，把OneHot后的特征加入进来，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##用pandas的get_dummies方法进行OneHot编码\n",
    "sex_onehot_df = pd.get_dummies(insurance.sex, prefix = \"sex\",drop_first=True)\n",
    "smoker_onehot_df = pd.get_dummies(insurance.smoker, prefix=\"smoker\",drop_first=True)\n",
    "region_onehot_df = pd.get_dummies(insurance.region, prefix=\"region\",drop_first=True)\n",
    "\n",
    "insurance_merged = pd.concat([insurance, sex_onehot_df, smoker_onehot_df, region_onehot_df], axis=1)\n",
    "\n",
    "pd.set_option(\"display.max_columns\",15)\n",
    "insurance_merged.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**分离X,y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 分离X，y\n",
    "drop_columns = ['charges','sex','smoker','region']\n",
    "X = insurance_merged.drop(drop_columns,axis=1)\n",
    "y = insurance_merged['charges']\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**划分train与test(7:3)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=77)\n",
    "print('训练集的规模:',len(X_train), '测试集的规模:', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**构建回归模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 构建线性回归模型\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rm指标\n",
    ">>|方法\t|说明|\n",
    "|---:|---:|\n",
    "|metrics.mean_absolute_error\t|平均绝对误差|\n",
    "|metrics.mean_squared_error\t|均方误差|\n",
    "|metrics.mean_squared_log_error\t|均方对数误差|\n",
    "|metrics.median_absolute_error\t|中值绝对误差|\n",
    "|metrics.r2_score\t|决定系数R^2|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 计算回归指标\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "## 模型预测\n",
    "y_pred_train = lr.predict(X_train)   # 使用train集数据进行预测\n",
    "y_pred = lr.predict(X_test)          # 使用test集数据进行预测\n",
    "\n",
    "## 回归效果评估\n",
    "print(\"训练集的均方误差: \", round(mean_squared_error(y_train,y_pred_train),3))\n",
    "print(\"训练集的平均绝对误差: \", round(mean_absolute_error(y_train,y_pred_train),3))\n",
    "print(\"训练集的中值绝对误差: \", round(median_absolute_error(y_train,y_pred_train),3))\n",
    "print(\"训练集的决定系数: \", round(r2_score(y_train,y_pred_train),3))\n",
    "print(\"-\"*30)\n",
    "print(\"测试集的均方误差: \", round(mean_squared_error(y_test, y_pred),3))\n",
    "print(\"测试集的平均绝对误差: \", round(mean_absolute_error(y_test, y_pred),3))\n",
    "print(\"测试集的中值绝对误差: \", round(median_absolute_error(y_test, y_pred),3))\n",
    "print(\"测试集的决定系数: \", round(r2_score(y_test, y_pred),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**↑♎分析：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 聚类指标\n",
    "> + (1)轮廓系数(无监督,无标签数据)\n",
    ">>  + <img src=\"./imgs/chap06/fig06_06.png\" width=70%>\n",
    ">>  + <img src=\"./imgs/chap06/fig06_06_1.png\" width=70%>\n",
    "> + (2)兰德指数(无监督,有标签用于评价)\n",
    ">>  + <img src=\"./imgs/chap06/fig06_07.png\" width=70%>\n",
    "> + (3)调整兰德指数(无监督,有标签用于评价)\n",
    ">> + <img src=\"./imgs/chap06/fig06_08.png\" width=70%>\n",
    "> + sklean中对应函数：\n",
    ">> (1) `metrics.silhouette_score()`:\n",
    "\n",
    "|参数\t|说明|\n",
    "|---:|---:|\n",
    "|X\t|特征数组，或当metric=‘precomputed’时，X为样本间距离的数组|\n",
    "|labels\t|预测标签|\n",
    "|metric\t|计算距离的指标，常用方法有：‘euclidean’（默认）和‘manhattan’等|\n",
    "|random_state\t|选取子集时设置的随机种子|\n",
    "\n",
    ">> (2) `metrics.adjusted_rand_score()`:\n",
    "\n",
    "|参数\t|说明|\n",
    "|---:|---:|\n",
    "|labels_true\t|真实标签|\n",
    "|labels_pred\t|预测标签|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "adjusted_rand_score??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据\n",
    "> **汽车款式数据集**\n",
    ">> 市面上的汽车种类繁多，令很多消费者难以选择，现有一份数据集Auto，根据每种汽车的参数，利用聚类算法来进行聚类，识别出相似的汽车，共392个样本\n",
    "\n",
    ">> |特征\t|说明|\n",
    "|---:|---:|\n",
    "|mpg\t|一加仑汽油能支持的英里数|\n",
    "|cylinders\t|气缸数|\n",
    "|displacement\t|引擎排量|\n",
    "|horsepower\t|引擎马力|\n",
    "|weight\t|重量|\n",
    "|accerleration\t|从0加速到60mph所需时间|\n",
    "|year\t|年份|\n",
    "|origin\t|生产地，1:美国 2:欧洲 3:日本|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 读取数据\n",
    "file3_path =\"./dataSets/data_chap6/Auto.csv\"\n",
    "auto = pd.read_csv(file3_path)\n",
    "auto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**数据预处理(1)： 连续型特征标准化**\n",
    "> + `'MPG','Displacement','Horsepower','Weight','Acceleration'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 对连续型变量进行Z-score标准化\n",
    "from ___________________ import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# 标准化以下特征数据\n",
    "auto[['MPG','Displacement','Horsepower','Weight','Acceleration']] = scaler.____________(auto[['MPG','Displacement','Horsepower','Weight','Acceleration']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**数据预处理(2)： 类别型变量OneHot**\n",
    "> + `'Cylinders','Year','Origin'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 对类别型变量进行Z-score标准化哑变量编码：\n",
    "auto_scaled = pd.get_dummies(__________,columns=____________)\n",
    "\n",
    "### 查看新数据\n",
    "auto_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means聚类:n_clusters=3,random_state=77\n",
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(n_clusters=3,random_state=77).fit(auto_scaled)    #为使复现效果与PPT效果相同，设置随机种子为77\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 样本标签和簇质心\n",
    "auto_label = ____________\n",
    "auto_cluster = ____________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画每个簇样本数的柱状图\n",
    "auto_label_dataframe = pd.DataFrame({'clusters':auto_label})\n",
    "auto_label_dataframe['clusters'] = auto_label_dataframe['clusters'].astype('category')\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "counts = sns.countplot(x=________,data=__________)\n",
    "counts.set(xlabel=\"Clusters\",ylabel=\"Count\",title='类别数量分布条形图')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cluster指标1:轮廓系数\n",
    "> + `silhouette_score(X,label)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 选择不同k值比较聚类效果\n",
    "from sklearn.metrics import silhouette_score\n",
    "for i in np.arange(2,7):\n",
    "    model = KMeans(____________,random_state=77).fit(__________)   \n",
    "    labels = model.labels_\n",
    "    print('轮廓系数(k=%d):'%(i),round(silhouette_score(_______,_______),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**↑♎分析：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cluster指标2：兰德系数\n",
    "> + `adjusted_rand_score(labels_true,labels_pred) `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1)使用double moon数据对不同剧聚类模型的兰德系数进行验证**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入make_moons数据集\n",
    "from sklearn.datasets import make_moons\n",
    "make_moons?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 使用double moon数据进行验证\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "### 生成double moon 数据\n",
    "X,y = make_moons(n_samples=200,noise=0.06,random_state=77)\n",
    "\n",
    "### 将X数据Z-score标准化：miue=0，delt=1\n",
    "from  sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 图显double moon\n",
    "plt.scatter(_________,___________)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) 分别使用'KMeans(n_cluters=2)'和'DBSCAN()'对double moon 进行聚类**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 分别使用'KMeans(n_cluters=2)'和'DBSCAN()'对double moon 进行聚类\n",
    "## 绘制簇分配结果图形\n",
    "fig, axes = plt.subplots(nrows=1,ncols=2,figsize=(10, 5),subplot_kw={'xticks':(),'yticks':()}) \n",
    "# 列出要使用的算法\n",
    "algorithm_s = [KMeans(n_clusters=2,random_state=77),DBSCAN()]\n",
    "\n",
    "for ax, algorithm in zip(axes,algorithm_s): \n",
    "    clusters = algorithm.fit_predict(X_scaled) \n",
    "    labels = algorithm.labels_\n",
    "    ax.scatter(X_scaled[:, 0],X_scaled[:, 1],c=clusters,cmap='Set3',s=20)   # c=clusters\n",
    "    ax.set_title(\"{} - ARI: {:.2f} - SIL: {:.2f}\".format(algorithm.__class__.__name__,\n",
    "                                                         adjusted_rand_score(____,_______),\n",
    "                                                         silhouette_score(_______,_______)\n",
    "                                                        )\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**↑♎分析：** 对比聚类结果可明显看出，DBSCAN效果明显好于KMeans，但ARI(调整兰德指数),SIL(轮廓系数)结论不同：\n",
    ">  + Kmeans的SIL为0.50，而DBSCAN的SIL为0.38,按照轮廓系数范围【-1，1】越大聚类越好的原则，该结论与实际相悖\n",
    ">  + Kmeans的ARI为0.45，而DBSCAN的ARI为1.00,按照调整兰德指数【-1，1】越大聚类越好的原则，该结论与实际相符\n",
    ">  + 故，使用轮廓系数评价聚类效果的缺点：在形状复杂的数据上效果并不理想。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型选择与model_selection模块\n",
    "> + 使用数据集1：汽车满意度数据集 `file1_path = \"./dataSets/data_chap6/car.csv\"`\n",
    "> + **数据准备：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "data = pd.read_csv(\"./dataSets/data_chap6/car.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**数据分离与划分：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用汽车满意度数据集，为了便于可视化图形的观察，根据客户满意类别将数据重新排序\n",
    "data_reord = data.sort_values(by='car_acceptability')\n",
    "\n",
    "## 分离X,y\n",
    "X = data_reord.drop(['car_acceptability'], axis=1)\n",
    "y = data_reord['car_acceptability']\n",
    "## 划分train，test\n",
    "X_train,X_test,y_train,y_test= train_test_split(X, y, test_size = 0.2, random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "##  交叉验证\n",
    "> + <img src=\"./imgs/chap06/fig06_09.png\" width=70%>\n",
    "> + <img src=\"./imgs/chap06/fig06_10.png\" width=70%>\n",
    "> + sklean中对应的分类器\n",
    ">> ●`model_selection.KFold`\t: k折交叉分类器  <br>\n",
    ">> ●`model_selection.StratifiedKFold`:分层k折交叉分类器 <br>\n",
    ">> ●`model_selection.ShuffleSplit`:打乱数据集后再划分 <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**定义函数：用于可视化交叉验证结果**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cv_indices(cv, X, y, ax, n_splits, lw=10):\n",
    "    \"\"\"\n",
    "    功能：可视化交叉验证结果.\n",
    "    返回：图\n",
    "    cv：交叉分类器\n",
    "    X：特征数据集\n",
    "    y：目标数据\n",
    "    ax：图对象\n",
    "    n_splits：k折数\n",
    "    lw：linewidths\n",
    "    \"\"\"\n",
    "    # 可视化交叉验证每次的训练集和测试集划分结果\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y)):\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # 绘制图形\n",
    "        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n",
    "                   c=indices, marker='_', lw=lw, cmap='Set1',\n",
    "                   vmin=-.2, vmax=1.2)\n",
    "\n",
    "    # 绘制数据集类别分布条\n",
    "    ax.scatter(range(len(X)), [ii + 1.5] * len(X),\n",
    "               c=y, marker='_', lw=lw, cmap='Set3')\n",
    "\n",
    "    # 加上标题和轴标签\n",
    "    yticklabels = list(range(n_splits)) + ['class']\n",
    "    ax.set(yticks=np.arange(n_splits+1) + .5, yticklabels=yticklabels,\n",
    "           xlabel='Sample index', ylabel=\"CV iteration\",ylim=[n_splits+1, -.2])\n",
    "    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "### Kfold与StratifiedKFold分类器\n",
    "> + `KFold`和`StratifiedKFold`的函数参数：\n",
    "\n",
    "|参数\t|说明|\n",
    "|---:|---:|\n",
    "|n_splits\t|k折数，最小为2|\n",
    "|shuffle\t|布尔值，设置在划分前是否打乱数据|\n",
    "|random_state\t|随机种子|\n",
    "\n",
    "> + `KFold`和`StratifiedKFold`常用方法 \n",
    "\n",
    "|方法\t|说明|\n",
    "|---:|---:|\n",
    "|get_n_splits\t|返回划分迭代次数，即k折数|\n",
    "|split\t|划分数据集为训练集和测试集|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**kf与skf分类数据集**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入KFold和StratifiedKFold\n",
    "from ______________  import KFold\n",
    "from ______________  import StratifiedKFold\n",
    "# 构建KCV(k-fold cross validation)模型:kf,skf\n",
    "kf = KFold(n_splits=3)\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "# 划分数据集\n",
    "kf.split(X,y)\n",
    "skf.split(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1)kf划分结果可视化：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#绘制Kfold划分结果图\n",
    "fig, ax = plt.subplots()\n",
    "plot_cv_indices(__, __, __, ___, _____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**↑♎分析：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) skf划分结果可视化：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#绘制StratifiedKFold划分结果图\n",
    "fig, ax = plt.subplots()\n",
    "plot_cv_indices(__, __, __, ___, _____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**↑♎分析：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3) shuffle=True的kf划分结果**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#绘制参数shuffle=True的Kfold划分结果图\n",
    "fig, ax = plt.subplots()\n",
    "ck = KFold(n_splits=3,random_state=0,shuffle=True)\n",
    "plot_cv_indices(ck, X, y, ax, n_splits=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**↑♎分析：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "### ShuffleSplit分类器\n",
    "> + 使用`ShuffleSplit`也会将数据打乱后再划分，且可以设置训练集和测试集的大小，<br>\n",
    "> + **与交叉验证区别的是：随机划分不能保证每折都不相同**\n",
    "\n",
    ">> `model_selection.ShuffleSplit()`函数参数:\n",
    ">>> |方法\t|说明|\n",
    "|---:|---:|\n",
    "|n_splits\t|划分迭代次数|\n",
    "|test_size\t|测试集比例（浮点数）或样本数量（整数）|\n",
    "|train_size\t|训练集比例（浮点数）或样本数量（整数）|\n",
    "|random_state\t|随机种子|\n",
    "\n",
    ">> `model_selection.ShuffleSplit`常用方法:\n",
    ">>> |方法\t|说明|\n",
    "|---:|---:|\n",
    "|get_n_splits\t|返回划分迭代次数|\n",
    "|split\t|划分数据集为训练集和测试集|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入ShuffleSplit\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "# 构建模型，参数：n_splits=3, test_size=.2,\n",
    "rs = ShuffleSplit(n_splits=3, test_size=.2, random_state=0)\n",
    "rs.split(X,y)\n",
    "\n",
    "print('划分次数：',rs.get_n_splits())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "## 根据交叉验证查看模型参数\n",
    "> 常用函数：\t\n",
    ">> ●`model_selection.cross_val_score`\t:根据交叉验证计算模型分数 <br>\n",
    "●`model_selection.cross_val_predict`\t:根据交叉验证得出预测值   <br>\n",
    "●`model_selection.learning_curve`\t:学习曲线   <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "### 根据交叉验证计算模型score\n",
    ">● `model_selection.cross_val_score()`\n",
    ">> |参数\t|说明|\n",
    "|---:|---:|\n",
    "|estimator\t|指定的模型|\n",
    "|X\t|数据集中的样本集|\n",
    "|y\t|真实标签|\n",
    "|scoring\t|指定评价指标的字符串，默认采用.score方法，可选参数'accuracy'、'f1'、'logloss'和'mean_squared_error'等|\n",
    "|cv\t|默认为3折交叉分类器，如果为整数即为指定的k值，也可直接指定k折交叉分类器|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入逻辑回归、cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# 构建模型，输出cv=5的,cross_val_score\n",
    "print('Cross validation score is:',cross_val_score(LogisticRegression(),X,y,cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**↑♎分析：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "### 根据交叉验证查看模型学习曲线\n",
    "> + 学习曲线：一种用来判断训练模型的一种方法，通过观察绘制出来的学习曲线图，可以直观的了解到模型处于一个什么样的状态，\n",
    "> + 如：过拟合（overfitting）或欠拟合（underfitting）以及增大训练集是否可以减小过拟合。\n",
    "> + <img src=\"./imgs/chap06/fig06_11.png\" width=70%>\n",
    "————————————————————————————————————————————————————————————\n",
    "> + <img src=\"./imgs/chap06/fig06_12.png\" width=70%>\n",
    "\n",
    ">> + 1.高偏差：训练集与验证集收敛，但是两者收敛后的正确率远小于我们的期望，所以模型属于**欠拟合**问题。\n",
    ">>> ★ 欠拟合时，需要增加模型的复杂度，比如，增加特征、增加树的深度、减小正则项等等，此时再增加数据量是不起作用的。\n",
    ">> + 2.高方差：训练集正确率高于期望值，验证集则低于期望值，两者之间有很大的间距，误差很大，对于新的数据集模型适应性较差，模型属于过拟合问题。\n",
    ">>> ★过拟合时，需要降低模型的复杂度，比如减小树的深度、增大分裂节点样本数、增大样本数、减少特征数等等。\n",
    ">> + 3.一个比较理想的学习曲线图应当是：低偏差、低方差，即收敛且误差小。<br>\n",
    "\n",
    "> ●`model_selection.learning_curve()`:\n",
    ">> |参数\t|说明|\n",
    "|---:|---:|\n",
    "|estimator\t|指定的模型|\n",
    "|X\t|训练集|\n",
    "|y\t|训练集对应的标签|\n",
    "|train_sizes\t|指定考察数据集的比例（浮点数）或数量（整数）|\n",
    "|cv\t|默认为3折交叉分类器，如果为整数即为指定的k值，也可直接指定k折交叉分类器|\n",
    "|scoring|\t|指定评价指标的字符串，默认采用.score方法，可选参数'accuracy'、'f1'、'logloss'和'mean_squared_error'等|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**绘制学习曲线的函数：**\n",
    "> 官方提供的脚本，参数意义：\n",
    ">> + `estimator`:所要考察的模型\n",
    ">> + `cv`：交叉验证生成器，默认`cv=None`，这里使用`ShuffleSplit()`分类器.<br>\n",
    ">> + `title`：图像的名字。<br>\n",
    ">> + `ylim：tuple, shape (ymin, ymax),` 可选的。定义绘制的最小和最大y值。<br>\n",
    ">> + `n_jobs `: 整数，可选并行运行的作业数（默认值为1）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 绘制学习曲线函数\n",
    "from sklearn.model_selection import learning_curve\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    " \n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    " \n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "'''\n",
    "# 官方实例\n",
    "# digits = load_digits()\n",
    "# X, y = digits.data, digits.target    # 加载样例数据\n",
    " \n",
    "# # 图一\n",
    "# title = r\"Learning Curves (Naive Bayes)\"\n",
    "# cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "# estimator = GaussianNB()    #建模\n",
    "# plot_learning_curve(estimator, title, X, y, ylim=(0.7, 1.01), cv=cv, n_jobs=1)\n",
    " \n",
    "# # 图二\n",
    "# title = r\"Learning Curves (SVM, RBF kernel, $\\gamma=0.001$)\"\n",
    "# cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "# estimator = SVC(gamma=0.001)    # 建模\n",
    "# plot_learning_curve(estimator, title, X, y, (0.7, 1.01), cv=cv, n_jobs=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制逻辑回归模型的学习曲线\n",
    "## 导入LogisticRegression和learning_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import learning_curve\n",
    "## 选择模型\n",
    "estimator = LogisticRegression(solver='lbfgs')     ## 模型选择逻辑回归\n",
    "## 选择分类器\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)   ## 分类器选择ShuffleSplit\n",
    "# learning_curve(estimator, X, y,cv=cv,train_sizes=np.linspace(.1, 1.0, 5))\n",
    "## 设置title\n",
    "title = r\"LearningCurves(LR,ShuffleSplit)\"\n",
    "## 绘制学习曲线\n",
    "plot_learning_curve(estimator, title, X, y, ylim=(0.7, 1.01),cv=cv,n_jobs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**↑♎分析：**模型选择`LogisticRegression`，分类器选择`ShuffleSplit`的学习曲线,如上图<br>\n",
    "从图中可得结论： 收敛程度没问题，但模型整体精度偏低，有点欠拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数调优\n",
    "> + 学习器模型中的两种参数：\n",
    ">>●模型参数：从数据中学习估计得到，如：线性回归中的系数 <br>\n",
    ">>●模型超参数：无法从数据中估计，需根据经验人工设置，如：k近邻算法中的k值<br>\n",
    "> + 参数调优，即调整**超参数**来提升模型的泛化性能，常用方法为：\n",
    ">>●网格搜索交叉验证（GridSearchCV）：以穷举的方式遍历所有可能的参数组合<br>\n",
    ">> + <img src=\"./imgs/chap06/fig06_13.png\" width=70%>\n",
    ">>●随机搜索交叉验证（RandomizedSearchCV）：依据某种分布对参数空间采样，随机的得到一些候选参数组合方案<br>\n",
    ">> + <img src=\"./imgs/chap06/fig06_14.png\" width=70%>\n",
    "\n",
    "> + sklearn中参数调优常用类:\n",
    ">> ●`model_selection.GridSearchCV`:\t网格搜索交叉验证 <br>\n",
    "●`model_selection.RandomizedSearchCV`:\t随机搜索交叉验证\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网格搜索\n",
    ">`model_selection.GridSearchCV()`参数：\n",
    ">>|参数\t|说明|\n",
    "|---:|---:|\n",
    "|estimator\t|指定的模型|\n",
    "|param_grid\t|关于参数名（键）和参数取值（值）的字典或字典的列表|\n",
    "|scoring\t|指定评价指标的字符串，默认采用.score方法，可选'accuracy'、'f1'、'logloss'和'mean_squared_error'等|\n",
    "|cv\t|默认为3折交叉分类器，如果为整数即为指定的k值，也可直接指定k折交叉分类器|\n",
    "\n",
    ">`model_selection.GridSearchCV()`属性：\n",
    ">> |属性\t|说明|\n",
    "|---:|---:|\n",
    "|cv_results_\t|输出以字典形式存储的每个参数组合的得分情况|\n",
    "|best_estimator_\t|输出筛选出来的最佳模型|\n",
    "|best_score_\t|最佳模型的性能评分|\n",
    "|best_params_\t|最佳参数组合|\n",
    "\n",
    ">`model_selection.GridSearchCV()`方法：\n",
    ">>|方法\t|说明|\n",
    "|---:|---:|\n",
    "|fit(X[,y])\t|执行参数优化|\n",
    "|predict(X)\t|使用筛选的最佳模型预测数据|\n",
    "|predict_prob(X)\t|使用筛选的最佳模型预测数据为各类别的概率|\n",
    "|score(X[,y])\t|通过给定的数据集判断筛选的最佳模型的预测性能|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**使用网格搜索预测客户汽车满意度**\n",
    "> 数据：`file_path = \"./dataSets/data_chap6/car.csv\" `  <br>\n",
    "模型：构建非线性支持向量机模型预测数据，即使用SVC    <br>\n",
    "参数：该模型中有两个重要参数`C`惩罚系数和`gamma`核宽度，尝试不同取值的组合   <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 导入数据  \n",
    "data = pd.read_csv(\"./dataSets/data_chap6/car.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 分离X,y\n",
    "X = data_reord.drop(['car_acceptability'], axis=1)\n",
    "y = data_reord['car_acceptability']\n",
    "## 划分train，test\n",
    "X_train,X_test,y_train,y_test= train_test_split(X, y, test_size = 0.2, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 构建SVC模型\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 构建param_grid={K:V}\n",
    "param_grid = {\"C\":[0.1, 1, 10, 100], 'gamma':[0.1, 1, 10, 100]}\n",
    "print(\"参数网格:\\n{}\".format(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s0: 导入GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# s1:  构建网格搜索模型\n",
    "grid_search = GridSearchCV(estimator=________,\n",
    "                           param_grid=_________,\n",
    "                           cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s2:  执行参数优化\n",
    "grid_search.fit(X_train,y_train)\n",
    "# s3: 通过给定的数据集(test)判断最佳模型的预测性能\n",
    "best_score = _____________________\n",
    "print(\"最佳模型在测试集上的正确率: {:.3f}\".format(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s4: 获取最优模型的参数\n",
    "print(\"最优参数: {}\".format(________________)) \n",
    "# s5: 最优交叉验证分数\n",
    "print(\"最优交叉验证分数: {:.3f}\".format(_________________))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**↑♎分析:注意：这里有两个最优score是不一样的：**\n",
    "> + （1）`grid_search.score(X_test, y_test)`:是最佳模型在给定的test集上的表现 <br>\n",
    "> + （2）`grid_search.best_score_`: 是最佳模型的经过K折CV的最优评分 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机网格搜索\n",
    "> `model_selection.RandomizedSearchCV()`参数：\n",
    ">> |参数 \t|说明|\n",
    "|---:|---:|\n",
    "|param_distributions\t|关于参数名（键）和参数分布（值）的字典或字典的列表，通常使用scipy.stats模块中提供的分布，如：scipy.expon指数分布和scipy.uniform均匀分布等|\n",
    "|n_iter\t|指定每个参数采样的数量|\n",
    "\n",
    "> **使用随机网格搜索预测客户汽车满意度:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy\n",
    "## 构建param_grid={K:V}\n",
    "param_grid = {'C': range(1,200,1), 'gamma':scipy.stats.expon()} \n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 构建随机网格搜索\n",
    "random_search = RandomizedSearchCV(SVC(), param_distributions=param_grid, cv=5, n_iter=10)\n",
    "random_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更详细的模型信息：\n",
    "```python\n",
    "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
    "          estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
    "  shrinking=True, tol=0.001, verbose=False),\n",
    "          fit_params=None, iid='warn', n_iter=10, n_jobs=None,\n",
    "          param_distributions={'C': range(1, 200), 'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001F4B962D978>},\n",
    "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
    "          return_train_score='warn', scoring=None, verbose=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 执行参数优化\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
    "          estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
    "  shrinking=True, tol=0.001, verbose=False),\n",
    "          fit_params=None, iid='warn', n_iter=10, n_jobs=None,\n",
    "          param_distributions={'C': range(1, 200), 'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001F4B962D978>},\n",
    "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
    "          return_train_score='warn', scoring=None, verbose=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 通过给定的数据集(test)判断最佳模型的预测性能\n",
    "best_score = random_search.score(X_test,y_test)\n",
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"最优模型在测试集上的预测正确率: {:.3f}\".format(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 最优模型的参数\n",
    "print(\"最优参数: {}\".format(random_search.best_params_)) \n",
    "print(\"最优交叉验证分数: {:.3f}\".format(random_search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**↑♎分析:注意：这里有两个最优score是不一样的：**\n",
    "> + （1）`random_search.score(X_test, y_test)`:是最佳模型在给定的test集上的表现 <br>\n",
    "> + （2）`random_search.best_score_`: 是最佳模型的经过K折CV的最优评分 <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 这里有两个最优是不一样的\n",
    "print(\"Test set score: {:.3f}\".format(random_search.score(X_test, y_test)))\n",
    "print(\"Best parameters: {}\".format(random_search.best_params_)) \n",
    "print(\"Best cross validation score: {:.3f}\".format(random_search.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 小结\n",
    "> 1. 各类模型的评价指标与sklearn.metircs\n",
    ">> 分类clf指标：\n",
    ">>> clf指标1：accuracy  <br>\n",
    "clf指标2：precision,recall,f1_score <br>\n",
    "clf指标3：confusion_matrix <br>\n",
    "clf指标4：classification_report <br>\n",
    "clf指标5：P-R curve <br>\n",
    "clf指标6：ROC&AUC <br>\n",
    "clf指标7：log_loss(交叉熵) <br>\n",
    "clf指标8：hinge_loss(合页，SVM) <br>\n",
    "\n",
    ">> 回归rm指标：\n",
    ">>> 平均绝对误差：metrics.mean_absolute_error\t  <br>\n",
    "均方误差：metrics.mean_squared_error\t   <br>\n",
    "均方对数误差：metrics.mean_squared_log_error\t   <br>\n",
    "中值绝对误差：metrics.median_absolute_error\t   <br>\n",
    "决定系数R^2： metrics.r2_score\t  <br>\n",
    "\n",
    ">> 聚类cluster指标：\n",
    ">>> 轮廓系数：silhouette_score  <br>\n",
    "兰德系数：rand index   <br>\n",
    "调整兰德系数：adjust rand index   <br>\n",
    "\n",
    "> 2. 模型的选择与sklearn.model_selection\n",
    ">> 交叉验证\n",
    ">>> KFold 与 StratifiedKflod    <br> \n",
    ">>> shuffle=True的KFold与ShuffleSplit    <br>\n",
    "\n",
    ">> 交叉验证中模型的情况\n",
    ">>> 查看模型得分：`cross_val_score(LogisticRegression(),X,y,cv=5))`    <br>\n",
    ">>> 查看学习曲线: `learning_curve(estimator, X, y,cv=cv,train_sizes=np.linspace(.1, 1.0, 5))`    <br>\n",
    ">>>> estimator: 模型； X，y:数据； cv：分类器(KFold,StratifiedKFold,ShuffleSplit)    <br>\n",
    ">>>> 根据曲线可评估模型的状态,如：欠拟合，过拟合等，以采取合适的策略进行调整。\n",
    "\n",
    ">> 模型参数调优（调的是超参)\n",
    ">>> 网络搜索：`GridSearchCV(SVC(),param_grid={K:V},cv=5)`    <br>\n",
    ">>> 随机网格搜索：`RandomizedSearchCV(SVC(), param_distributions=param_grid, cv=5, n_iter=10)`   <br>\n",
    ">>>> 参数如下：所用模型，KV形式的参数网格，cv为KFold CV(cross validation) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Chap06_1_Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "369px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
