{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#数据读取\" data-toc-modified-id=\"数据读取-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>数据读取</a></span></li><li><span><a href=\"#探索性数据分析\" data-toc-modified-id=\"探索性数据分析-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>探索性数据分析</a></span></li><li><span><a href=\"#数据预处理\" data-toc-modified-id=\"数据预处理-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>数据预处理</a></span><ul class=\"toc-item\"><li><span><a href=\"#数值编码\" data-toc-modified-id=\"数值编码-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>数值编码</a></span></li><li><span><a href=\"#独热编码\" data-toc-modified-id=\"独热编码-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>独热编码</a></span></li><li><span><a href=\"#分离X与y\" data-toc-modified-id=\"分离X与y-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>分离X与y</a></span></li></ul></li><li><span><a href=\"#建模并评估\" data-toc-modified-id=\"建模并评估-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>建模并评估</a></span><ul class=\"toc-item\"><li><span><a href=\"#split-train-and-test\" data-toc-modified-id=\"split-train-and-test-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>split train and test</a></span></li><li><span><a href=\"#批量建模比对\" data-toc-modified-id=\"批量建模比对-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>批量建模比对</a></span><ul class=\"toc-item\"><li><span><a href=\"#K-近邻、逻辑回归和支持向量机\" data-toc-modified-id=\"K-近邻、逻辑回归和支持向量机-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>K-近邻、逻辑回归和支持向量机</a></span></li><li><span><a href=\"#决策树和三种朴素贝叶斯\" data-toc-modified-id=\"决策树和三种朴素贝叶斯-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>决策树和三种朴素贝叶斯</a></span></li></ul></li><li><span><a href=\"#模型优化与筛选\" data-toc-modified-id=\"模型优化与筛选-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>模型优化与筛选</a></span><ul class=\"toc-item\"><li><span><a href=\"#逻辑回归调参\" data-toc-modified-id=\"逻辑回归调参-4.3.1\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>逻辑回归调参</a></span></li><li><span><a href=\"#K-近邻调参\" data-toc-modified-id=\"K-近邻调参-4.3.2\"><span class=\"toc-item-num\">4.3.2&nbsp;&nbsp;</span>K-近邻调参</a></span></li><li><span><a href=\"#决策树调参\" data-toc-modified-id=\"决策树调参-4.3.3\"><span class=\"toc-item-num\">4.3.3&nbsp;&nbsp;</span>决策树调参</a></span></li></ul></li><li><span><a href=\"#选用最优模型(决策树)再分析\" data-toc-modified-id=\"选用最优模型(决策树)再分析-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>选用最优模型(决策树)再分析</a></span><ul class=\"toc-item\"><li><span><a href=\"#输出模型参数\" data-toc-modified-id=\"输出模型参数-4.4.1\"><span class=\"toc-item-num\">4.4.1&nbsp;&nbsp;</span>输出模型参数</a></span></li><li><span><a href=\"#决策树模型特征重要性\" data-toc-modified-id=\"决策树模型特征重要性-4.4.2\"><span class=\"toc-item-num\">4.4.2&nbsp;&nbsp;</span>决策树模型特征重要性</a></span></li><li><span><a href=\"#决策树模型可视化\" data-toc-modified-id=\"决策树模型可视化-4.4.3\"><span class=\"toc-item-num\">4.4.3&nbsp;&nbsp;</span>决策树模型可视化</a></span></li></ul></li></ul></li><li><span><a href=\"#小结\" data-toc-modified-id=\"小结-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>小结</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sklearn04_2_利用分类模型预测学生成绩等级**\n",
    "\n",
    ">**案例描述:**\n",
    ">>本案例为《机器学习实践》课程第四章分类模型配套案例。数据来自手机APP\"Kalboard 360\"的学习管理系统（LMS）。Kalboard 360旨在利用尖端技术来提升学校K-12教育的教育水平。该数据集的收集来自两个学期：第一学期收集了245个学生记录，第二学期收集了235个学生记录。共计480个学生记录，每条记录包含16个特征组。这些特征分为三大类：<br>\n",
    ">>>Features_class1:性别和国籍等人口统计特征。<br>\n",
    "Features_class2:如教育阶段，年级和隶属教室。<br>\n",
    "Features_class3:如上课举手，访问资源，家长回答问卷调查，学校满意度等。<br>\n",
    "Result_Class:最后依据总成绩被分为三类：低：0-69、中：70-89、高：90-100。<br>\n",
    "\n",
    "\n",
    ">**数据集:**\n",
    ">> 本地地址：`data_path = './dataSets/data_chap4/EduData.csv'` <br>\n",
    ">>数据字段及说明：\n",
    "\n",
    "| 特征                     \t| 说明                                                                                                      \t|\n",
    "|--------------------------\t|-----------------------------------------------------------------------------------------------------------\t|\n",
    "| gender                   \t| 学生性别（ 'Male' or 'Female’）                                                                           \t|\n",
    "| NationalITy              \t| 学生国籍                                                                                                  \t|\n",
    "| PlaceofBirth             \t| 学生的出生地                                                                                              \t|\n",
    "| StageID                  \t| 受教育水平（‘lowerlevel’,’MiddleSchool’,’HighSchool’）                                                    \t|\n",
    "| GradeID                  \t| 年级（‘G-01’, ‘G-02’, ‘G-03’,   ‘G-04’, ‘G-05’, ‘G-06’, ‘G-07’, ‘G-08’, ‘G-09’, ‘G-10’, ‘G-11’, ‘G-12 ‘） \t|\n",
    "| SectionID                \t| 隶属的教室（’A’,’B’,’C’）                                                                                 \t|\n",
    "| Topic                    \t| 课程名                                                                                                    \t|\n",
    "| Semester                 \t| 学校的学期（’ First’,’ Second’）                                                                          \t|\n",
    "| Relation                 \t| 监护学生的家长（’mom’,’father’）                                                                          \t|\n",
    "| raisedhands              \t| 学生在教室中举手次数（0-100）                                                                             \t|\n",
    "| VisITedResources         \t| 学生访问在线课程次数（0-100）                                                                             \t|\n",
    "| AnnouncementsView        \t| 学生检查新公告的次数（0-100）                                                                             \t|\n",
    "| Discussion               \t| 学生参加讨论组的次数（0-100）                                                                             \t|\n",
    "| ParentAnsweringSurvey    \t| 家长是否回答了学校提供的调查问卷（’Yes’,’No’）                                                            \t|\n",
    "| ParentschoolSatisfaction \t| 家长对学校的满意度（’Yes’,’No’）                                                                          \t|\n",
    "| StudentAbsenceDays       \t| 每个学生的缺勤天数（'above-7', 'under-7'）                                                                    \t|\n",
    "| Class                    \t| 根据学生的总成绩分为三个等级（低分：0-69，中等分数：70-89，高分：90-100）                              \t|\n",
    "> **任务：**\n",
    ">> **本项目任务是根据收集的数据预测学生的成绩等级。**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0.导入包**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.导入基础包\n",
    "## 1.1 三剑客\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1.2 设置正常显示中文及负号\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']    # 正常显示中文\n",
    "plt.rcParams['axes.unicode_minus'] = False     # 正常显示负号\n",
    "\n",
    "# 2.导入Sk数据预处理包\n",
    "## 2.1 数值编码\n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "## 2.2 train与test划分\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 3.导入Sk模型包\n",
    "## 已学过的各种分类模型\n",
    "from __________________ import LogisticRegression\n",
    "from __________________ import KNeighborsClassifier\n",
    "from __________________ import DecisionTreeClassifier\n",
    "from __________________ import BernoulliNB\n",
    "from __________________ import GaussianNB\n",
    "from __________________ import MultinomialNB\n",
    "from __________________ import LinearSVC\n",
    "from __________________ import SVC\n",
    "\n",
    "# 4.导入Sk模型评价包\n",
    "from __________________ import accuracy_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 忽略警告\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据\n",
    "data_path = './dataSets/data_chap4/EduData.csv'\n",
    "edm = __________________\n",
    "# 查询前5行\n",
    "edm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 探索性数据分析\n",
    "\n",
    ">首先，我们来查看一下数据集的基本信息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 数据集基本信息info()\n",
    "edm.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑♎：可以看到数据中不存在缺失值，但列名中有些字母大小写不统一，为方便我们统一改为首字母大写，其余小写："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改列名,原位修改\n",
    "edm.rename(columns={'gender':'Gender', 'NationalITy':'Nationality',\n",
    "                    'raisedhands':'RaisedHands', 'VisITedResources':'VisitedResources'},\n",
    "                    __________________)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 修改列名\n",
    "# edm.rename(index=str, columns={'gender':'Gender', 'NationalITy':'Nationality',\n",
    "#                                'raisedhands':'RaisedHands', 'VisITedResources':'VisitedResources'},\n",
    "#                                inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再次查看特征名\n",
    "edm.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↓♎：接下来我们通过可视化来进一步挖掘数据中包含的信息，首先来看3个成绩等级的数量分布情况："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计目标类别'Class'中每个种类的样本数量\n",
    "edm['Class']__________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 绘制条形图，显示'Class'特征情况\n",
    "plt.figure(figsize=(8, 6))\n",
    "counts = sns.countplot(__________, ___________, palette='coolwarm')\n",
    "counts.set(xlabel='Class', ylabel='Count', title='Occurences per class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑♎：可以看到虽然成绩中等的学生要比其余两个成绩等级的学生多一些，但数据集不存在类别分布极端不平衡的情况。\n",
    "\n",
    "↓♎：继续查看学生的国籍分布情况："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 绘制条形图,显示'Nationality'特征情况\n",
    "plt.figure(figsize=(8, 6))\n",
    "nat = sns.__________(__________, __________, palette='coolwarm')\n",
    "nat.set(xlabel='Nationality', ylabel='Count', title='Nationality Representation')\n",
    "plt.setp(nat.get_xticklabels(), rotation=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑♎：数据集中的学生分别来自14个国家，大多数学生来自科威特或约旦。\n",
    "\n",
    "↓♎：下面再来看看两个不同学期间，学生成绩等级的数量分布差异："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 绘制条形图,hue参数是用来控制第三个变量的颜色显示。\n",
    "plt.figure(figsize=(8, 6))\n",
    "sem = sns.countplot(__________, __________, __________, order=['L', 'M', 'H'],  palette='coolwarm')\n",
    "sem.set(xlabel='Class', ylabel='Count', title='Semester comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑♎：学生在第二学期（'S'）的表现比第一学期（'F'）好一些。 在第二学期，成绩中等的学生人数保持不变，但是成绩差的学生人数较少，而成绩好的学生人数较多。 \n",
    "\n",
    "↓♎：接着来看看不同性别之间，学生成绩等级的数量分布差异："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 绘制条形图\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot = sns.countplot(__________, __________, __________, order=['L', 'M', 'H'], palette='coolwarm')\n",
    "plot.set(xlabel='Class', ylabel='Count', title='Gender comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑♎：可以看到学生中男生较多，并且较女生而言，男生低分成绩的人较多，高分成绩的人较少。\n",
    "\n",
    "↓♎：再来看看不同性别之间，访问在线教学资源次数的多少会不会影响学生的成绩等级,即：x='Class', y='VisitedResources'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 绘制蜂窝点图(swarmplot)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot = sns.__________(__________, __________, __________, __________,\n",
    "                      order=['L', 'M', 'H'], palette='coolwarm')\n",
    "plot.set(xlabel='Class', ylabel='Count', title='Gender comparison on visited resources')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑♎：上图显示获得低分（L）的学生比获得中等分数（M）或高分（H）的学生访问的资源少的多。此外，获得高分（H）的女性几乎都访问了很多在线资源。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理\n",
    "\n",
    "> + 从数据集的基本信息中可以看到，有些特征的类型是字符型，需要在建模前做一些预处理。\n",
    "> + **注意区分**数值编码与独热编码的适用范围,请试着回答一下？？？ \n",
    "> + 有序/无序分类特征\n",
    "\n",
    "## 数值编码\n",
    "> + 使用`LabelEncoder()`对字符型特征进行数值编码：<br>\n",
    "> + 注意：'Class'特征中的【H,M,L】会转成数值【0,2,1】,按字母升序转换\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LabelEncoder()知识点体会：\n",
    "\n",
    "# 模型构建\n",
    "le = _____________\n",
    "\n",
    "# 模型训练\n",
    "le.fit([\"H\", \"M\",\"M\", \"L\"])\n",
    "\n",
    "# 输出编码后类属性(即str对应的num)\n",
    "print(list(le.classes_))\n",
    "\n",
    "# 模型transform()\n",
    "le.transform([\"H\", \"L\", \"M\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将类别数值反向转成str\n",
    "le.____________([0, 2, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑♎思考：LabelEncoder()可将`str`类转成`num`类，但有时并不一定符合我们的要求，如果想实现`L:0,M:1,H:2`,可使用哪种方法实现？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 考察哪些特征需要进行LabelEncoder\n",
    "## 查看edm的特征类型\n",
    "edm._______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 选出需要进行数值编码的特征：即所有的 'object'类型的特征名\n",
    "str_columns = _____________________\n",
    "str_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 遍历str_columns中的所有特征，逐个转成数值编码\n",
    "for col in str_columns:\n",
    "    edm[col] = _______.______________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 选出dtypes=='object'的特征\n",
    "# edm.dtypes\n",
    "# edm.dtypes == 'object'\n",
    "# edm.dtypes[edm.dtypes == 'object']\n",
    "# edm.dtypes[edm.dtypes == 'object'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再次查看 LabelEncoder()后的数据\n",
    "edm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 独热编码\n",
    ">为方便后续建立模型，需要对除去目标特征之外的无序分类特征进行独热编码：\n",
    ">> `StageID`:受教育水平（‘lowerlevel’,’MiddleSchool’,’HighSchool’）有顺序关系。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 独热编码，除了特征['Class', 'StageID']外，其他都转One-Hot\n",
    "edm_new = pd._______(_______, columns=______________)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 查看独热编码后的维度\n",
    "edm_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看基本统计信息\n",
    "edm_new.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**↑♎分析**：以上预处理工作已经完成，因为特征之间没有数量级的差异，所以未进行数据标准化(Z-,MinMax)，下面进行建模工作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分离X与y\n",
    "> 将目标与数据分离，准备建立模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 分离目标, axis=1或者'columns'\n",
    "X_new = _______\n",
    "y_new = _______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建模并评估\n",
    "\n",
    "## split train and test\n",
    "> + 首先将数据集划分为训练集和测试集，比例为4:3，random_state=77,注意stratify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(_______,_______,\n",
    "                                                 test_size=0.25,\n",
    "                                                 random_state=77,\n",
    "                                                 ______________)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 批量建模比对\n",
    "> + 通过前面的学习可知，机器学习的过程为：**(1) 模型创建==>(2)训练fit()==>(3)预测predict()==>(4)评价acc、report、confusion_matrix==>(5)优化；**<br>\n",
    "> + 在这几个过程中，除了步骤(5)优化差异大一些外，其他过程代码基本相同，为了提高代码效率，这里编写model的通用代码,进行批量建模和评价。<br>\n",
    "\n",
    "### K-近邻、逻辑回归和支持向量机\n",
    "> + ▶建立逻辑回归、K-近邻和支持向量机(LinearSVC,SVC)模型，并输出测试集的分类正确率和分类报告："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 批量建模并评估\n",
    "\n",
    "## 模型字典\n",
    "models = {'逻辑回归': LogisticRegression(),\n",
    "          'K-近邻': KNeighborsClassifier(),\n",
    "          '线性支持向量机': LinearSVC(),\n",
    "          '支持向量机': SVC()}\n",
    "\n",
    "model_scores= []     # 存放每个模型的acc\n",
    "model_names=[]       # 存放每个模型的name\n",
    "\n",
    "\n",
    "for k,v in models.items():\n",
    "    # s1:模型构建\n",
    "    clf = _______\n",
    "    # s2:模型训练\n",
    "    clf._______\n",
    "    # s3:模型预测\n",
    "    y_pred = _______\n",
    "    \n",
    "    # s4:模型评估\n",
    "    print(str(k)+\"建模效果：\\n\")\n",
    "    # s4-1:模型评估-分类报告\n",
    "    report = classification_report(_______,_______,target_names=['H','L','M'])  # 如果不设置`target_name`则显示【0,1,2】\n",
    "    print(report) \n",
    "    # s4-2:模型评估-分类报告\n",
    "    acc = accuracy_score(_______,_______) # 与acc=clf.score(X_test,y_test)结果相同,如果不想predict()只要acc就可以用clf.score()\n",
    "    print(\"分类正确率为:\"+ str(acc))\n",
    "    # 将acc添加到model_scores中\n",
    "    model_scores._______\n",
    "    # 将当下模型的名称添加到model_names中\n",
    "    model_names._______\n",
    "    \n",
    "    # s4-3:模型评估-混淆矩阵+绘制热力图\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    ax = sns.heatmap(_____________________, \n",
    "                     annot=True, fmt='d', \n",
    "                     xticklabels=[\"H\",\"L\",'M'], \n",
    "                     yticklabels=[\"H\",\"L\",'M'])\n",
    "    ax.set_ylabel('真实')\n",
    "    ax.set_xlabel('预测')\n",
    "    ax.set_title(str(k)+'混淆矩阵热力图')\n",
    "    plt.yticks(rotation=360)    # 将y轴字体进行旋转\n",
    "    plt.show() \n",
    "    print('\\n\\n')\n",
    "\n",
    "# 将上述4个模型的Acc构建一个DF\n",
    "df1 = pd.DataFrame({'model':_______,\"Acc\":_______})\n",
    "df1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑♎分析：从上表看到，逻辑回归的预测效果比较好，其次是LinearSVC，再次是K-近邻。\n",
    "\n",
    "↓♎接下来我们建立决策树和三种朴素贝叶斯模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  决策树和三种朴素贝叶斯\n",
    ">▶建立决策树和三种朴素贝叶斯模型:\n",
    ">> `DecisionTreeClassfier()`<br>\n",
    "`GaussianNB()`<br>\n",
    "`BernoulliNB()`<br>\n",
    "`MultinomialNB()`<br>\n",
    "\n",
    "> 代码与前一节类似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 建模并评估\n",
    "\n",
    "# 模型字典\n",
    "models = {'决策树': DecisionTreeClassifier(),\n",
    "          '高斯贝叶斯': GaussianNB(),\n",
    "          '伯努利贝叶斯': BernoulliNB(),\n",
    "          '多项式贝叶斯': MultinomialNB()}\n",
    "\n",
    "\n",
    "model_scores= []     # 存放每个模型的acc\n",
    "model_names=[]       # 存放每个模型的name\n",
    "\n",
    "for k,v in models.items():\n",
    "    mod = v\n",
    "    #**********#\n",
    "    \n",
    "    \n",
    "    #**********#\n",
    "\n",
    "df2 = pd.DataFrame({'model':model_names,\"Acc\":model_scores})\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑♎分析：上表可以看到决策树、伯努利朴素贝叶斯模型效果较好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型优化与筛选\n",
    ">对两次建模效果比较好的三种模型：逻辑回归模型、K-近邻、决策树进行调参，看看能否进一步提升模型的效果。(伯努利朴素贝叶斯模型暂不作调整)\n",
    "\n",
    "###  逻辑回归调参\n",
    "> 原模型：<br>\n",
    "`LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
    "          n_jobs=None, penalty='l2', random_state=77, solver='lbfgs',\n",
    "          tol=0.0001, verbose=0, warm_start=False)`<br>\n",
    "          \n",
    "> 调优途径：<br>\n",
    "对`LogisticRegression`类中的参数`C`、`penalty`和`class_weight`进行调整："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " LogisticRegression??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建超参的网格列表\n",
    "\n",
    "#超参1： 创建一个包含不同C取值的列表\n",
    "C_grid = [0.2, 0.4, 0.6, 0.8, 1, 1.2, 1.4, 1.6, 1.8]\n",
    "#超参2： 创建一个包含不同penalty取值的列表，注意sklearn0.22版本后，该参数有所改变，即\"solver='lbfgs'\"只能用l2\n",
    "# penalty_grid  = [\"l2\", \"l1\"]\n",
    "penalty_grid  = [\"l2\"]\n",
    "#超参3： 创建一个包含不同class_weight取值的列表\n",
    "class_weight_grid = ['balanced', None]\n",
    "\n",
    "# 超参组合成元组列表\n",
    "parameter_s=[(C_, penalty_, class_weight_) __________   __________   __________]\n",
    "parameter_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 参数调优，记录每组特定参数下模型的acc\n",
    "result_acc = {}  # 存放某一组参数下的Acc,如：(0.2, 'l2', 'balanced'):0.77\n",
    "\n",
    "for parameter in parameter_s:\n",
    "    result_acc[parameter] = LogisticRegression(C=_________,penalty=_________,\n",
    "                                               class_weight=_________,\n",
    "                                               random_state=77,)._________._________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出result_acc\n",
    "for k,v in result_acc.items():\n",
    "    print(k,\":\",v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造DF存放result_acc，按Acc降序输出，前5个\n",
    "df1 = pd.DataFrame({\"parameter_list\":list(result_acc.keys()),\n",
    "                   \"Acc\":list(result_acc.values())}).sort_values(by=\"Acc\",ascending=False)[:5] \n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重置df的索引\n",
    "df1.________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑♎分析：与4.2.1节中的结果进行比较，可看出当正则化强度为1.8，采用L2正则化项，模型效果提升有所提升。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 另一种生成df的方法：\n",
    "# df1 = pd.DataFrame(list(result_acc.items()),\n",
    "#                       columns=['parameter_list', 'accuracy']).sort_values(by='accuracy', ascending=False)[:5]\n",
    "# df1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  K-近邻调参\n",
    "> 原模型：<br>\n",
    "`▶ KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
    "           weights='uniform')`\n",
    "           \n",
    ">调优途径：<br>\n",
    "对`KNeighborsClassifier`类中的参数`n_neighbors`和`weights`进行调整："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#超参1： 创建一个包含不同n_neighbors取值的列表\n",
    "n_grid = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "#超参2： 创建一个包含不同weights取值的列表\n",
    "weights_grid  = [\"uniform\", \"distance\"]\n",
    "\n",
    "# 超参组合成元组列表\n",
    "parameter_s = [(n_, weights_) _____________   ___________]\n",
    "parameter_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 参数调优，记录每组特定参数下模型的acc\n",
    "result_acc = {}\n",
    "\n",
    "for parameter in parameter_s:\n",
    "    n = parameter[0]\n",
    "    w = parameter[1]\n",
    "    result_acc[parameter] = KNeighborsClassifier(_____________,_____________).fit(X_train,y_train).score(X_test,y_test)\n",
    "    \n",
    "result_acc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 构建df                                                    \n",
    "df2 = pd.DataFrame(list(result_acc.items()),\n",
    "                  columns=['parameter_list', 'accuracy']).sort_values(by='accuracy', ascending=False)[:5]\n",
    "# 重置df的索引\n",
    "df2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑♎分析：与4.2.1节中的结果进行比较，可以看到：\n",
    "> + (1) 近邻样本个数为4，K-近邻模型效果有所提升，效果不明显。<br> \n",
    "> + (2) 近邻样本个数为5，K-近邻与加权K-近邻模型效果一致，且与之前持平，总体上来讲，效果不明显。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树调参\n",
    "> 原模型：<br>\n",
    "`DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=10,\n",
    "            splitter='best')`\n",
    "            \n",
    ">调优途径：<br>\n",
    "对`DecisionTreeClassifier`类中的参数`criterion`、`max_depth`和`class_weight`进行调整："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个包含不同criterion取值的列表\n",
    "criterion_grid = ['gini', 'entropy']\n",
    "\n",
    "# 创建一个包含不同max_depth取值的列表\n",
    "depth_grid = [1, 2, 3, 4, 5, 6, 7, 8, None]\n",
    "\n",
    "# 创建一个包含不同class_weight取值的列表\n",
    "class_weight_grid = ['balanced', None]\n",
    "\n",
    "# 组合成元组列表\n",
    "parameter_s = [(criterion_, depth_, weights_) for criterion_ in criterion_grid for depth_ in depth_grid for weights_ in class_weight_grid]\n",
    "parameter_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 参数调优\n",
    "result_acc={}\n",
    "\n",
    "for parameter in parameter_s:\n",
    "    result_acc[parameter] = DecisionTreeClassifier(criterion=__________, \n",
    "                                                   max_depth=__________, \n",
    "                                                   class_weight=__________,\n",
    "                                                   random_state=77\n",
    "                                                   )._______________.______________\n",
    "result_acc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 构建df                                                    \n",
    "df3 = pd.DataFrame(list(result_acc.items()),\n",
    "                  columns=['parameter_list', 'accuracy']).sort_values(by='accuracy', ascending=False)[:5]\n",
    "df3.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑♎分析：当采用Gini系数计算不纯度，最大树深度设为5且不平衡样本分类权重时，模型效果提升最明显, 正确率达到了79%，是目前最好的模型。后面继续对(gini, 5, None)参数的DecisionTreeClassifier()进一步分析。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 选用最优模型(决策树)再分析\n",
    "> 利用选出的最佳参数(gini, 5, None)建立模型DecisionTreeClassifier(),进而进行模型参数可视化、特征重要性及决策树可视化操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出模型参数\n",
    "> **输出(gini,5,None)的`DecisionTreeClassifier()`的`report`和`confusion_matrix`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立DTC决策树模型并训练\n",
    "DTC = _________________________\n",
    "DTC.fit(X_train,y_train)\n",
    "y_pred = _________________________\n",
    "acc = _________________________\n",
    "print(\"分类正确率acc:\",acc)\n",
    "\n",
    "report = classification_report(_______,________,target_names=['H','L','M'])  # ['H','L','M'] VS [0,1,2]\n",
    "print(\"分类报告：\\n\",report)\n",
    "\n",
    "## 输出混淆矩阵热力图\n",
    "plt.figure(figsize=(8,6))\n",
    "ax = sns.heatmap(_____________________,\n",
    "                 ___________,fmt='d',\n",
    "                 xticklabels=['H','L','M'],\n",
    "                 yticklabels=['H','L','M']\n",
    "                )\n",
    "ax.set_ylabel(\"真实值\")\n",
    "ax.set_xlabel(\"预测值\")\n",
    "ax.set_title(\"混淆矩阵热力图\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑♎分析：从分类report和confusion_matrix的heatmap可看出，H类和M类的预测效果相近，L类的预测效果较H类和M类较好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树模型特征重要性\n",
    ">再次利用选出的最佳参数建立模型，并输出特征重要性："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看最优模型的参数重要性系数的arr\n",
    "DTC._________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看以上arr的shape\n",
    "DTC._______________._______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取出X_train的特征名称，准备构建Series\n",
    "index = X_train.columns\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 特征重要性,取前5个最大的\n",
    "fea_imp = pd.Series(DTC._______________, index=_______________).sort_values(ascending=False)[:5]\n",
    "fea_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑♎分析：可以看到学生缺勤的天数`StudentAbsenceDays`、访问在线课程次数`VisitedResources`、检查新公告的次数`AnnouncementsView`、举手次数`RaisedHands`和监护人`Relation`这5个特征最为重要。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树模型可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 决策树可视化\n",
    "## 导入必要库\n",
    "from sklearn.tree import export_graphviz\n",
    "# from sklearn.externals.six import StringIO\n",
    "from six import StringIO\n",
    "from IPython.display import Image \n",
    "import pydotplus\n",
    "\n",
    "## 输出图片到dot文件\n",
    "export_graphviz(DTC, out_file='tree.dot', \n",
    "                feature_names=X_train.columns,\n",
    "                rounded=True, filled=True,\n",
    "                class_names=['H', 'L','M'])\n",
    "\n",
    "## 使用dot文件构造图\n",
    "graph= pydotplus.graph_from_dot_file('tree.dot')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 小结\n",
    ">至此，我们通过探索性数据分析、数据预处理、模型选择和参数调优，最终建立了决策树模型来预测学生的成绩等级。<br>\n",
    "对于其他模型，如伯努利朴素贝叶斯模型的优化可自行进行分析。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "286px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
